{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29e7bb1f-dd74-4a7f-ba2d-40489f10d332",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=7405609722860900#setting/sparkui/1227-144843-07llbp97/driver-3317347774000518291\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f59e4176450>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2587646e-1687-4d06-b7d6-80209627a8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze Layer â€“ Raw Data Ingestion\n",
    "\n",
    "The Bronze layer is responsible for ingesting raw e-commerce data from the source into the data lake without applying any transformations.  \n",
    "This ensures that the original data is preserved for traceability, reprocessing, and auditing purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b530f02e-8e79-4697-9d20-f46750bd8d79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='abfss://olist-data@retailds.dfs.core.windows.net/bronze/', name='bronze/', size=0, modificationTime=1766773696000),\n",
       " FileInfo(path='abfss://olist-data@retailds.dfs.core.windows.net/gold/', name='gold/', size=0, modificationTime=1766773719000),\n",
       " FileInfo(path='abfss://olist-data@retailds.dfs.core.windows.net/raw/', name='raw/', size=0, modificationTime=1766773686000),\n",
       " FileInfo(path='abfss://olist-data@retailds.dfs.core.windows.net/silver/', name='silver/', size=0, modificationTime=1766773707000)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the files in the olist-data container\n",
    "dbutils.fs.ls(\"abfss://olist-data@retailds.dfs.core.windows.net/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0140744-fede-4903-9f86-8b67108b6138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Source\n",
    "- Dataset: Olist Brazilian E-Commerce Dataset\n",
    "- Storage: Azure Data Lake Storage Gen2\n",
    "- Format: CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "971ad16f-9ffb-4c07-b529-6d244d9d397d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the orders csv file from raw/olist/ folder\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"abfss://olist-data@retailds.dfs.core.windows.net/raw/olist/olist_orders_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c563ce-73ca-4ab2-943f-de10a29d64c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>order_id</th><th>customer_id</th><th>order_status</th><th>order_purchase_timestamp</th><th>order_approved_at</th><th>order_delivered_carrier_date</th><th>order_delivered_customer_date</th><th>order_estimated_delivery_date</th></tr></thead><tbody><tr><td>e481f51cbdc54678b7cc49136f2d6af7</td><td>9ef432eb6251297304e76186b10a928d</td><td>delivered</td><td>2017-10-02T10:56:33Z</td><td>2017-10-02T11:07:15Z</td><td>2017-10-04T19:55:00Z</td><td>2017-10-10T21:25:13Z</td><td>2017-10-18T00:00:00Z</td></tr><tr><td>53cdb2fc8bc7dce0b6741e2150273451</td><td>b0830fb4747a6c6d20dea0b8c802d7ef</td><td>delivered</td><td>2018-07-24T20:41:37Z</td><td>2018-07-26T03:24:27Z</td><td>2018-07-26T14:31:00Z</td><td>2018-08-07T15:27:45Z</td><td>2018-08-13T00:00:00Z</td></tr><tr><td>47770eb9100c2d0c44946d9cf07ec65d</td><td>41ce2a54c0b03bf3443c3d931a367089</td><td>delivered</td><td>2018-08-08T08:38:49Z</td><td>2018-08-08T08:55:23Z</td><td>2018-08-08T13:50:00Z</td><td>2018-08-17T18:06:29Z</td><td>2018-09-04T00:00:00Z</td></tr><tr><td>949d5b44dbf5de918fe9c16f97b45f8a</td><td>f88197465ea7920adcdbec7375364d82</td><td>delivered</td><td>2017-11-18T19:28:06Z</td><td>2017-11-18T19:45:59Z</td><td>2017-11-22T13:39:59Z</td><td>2017-12-02T00:28:42Z</td><td>2017-12-15T00:00:00Z</td></tr><tr><td>ad21c59c0840e6cb83a9ceb5573f8159</td><td>8ab97904e6daea8866dbdbc4fb7aad2c</td><td>delivered</td><td>2018-02-13T21:18:39Z</td><td>2018-02-13T22:20:29Z</td><td>2018-02-14T19:46:34Z</td><td>2018-02-16T18:17:02Z</td><td>2018-02-26T00:00:00Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "e481f51cbdc54678b7cc49136f2d6af7",
         "9ef432eb6251297304e76186b10a928d",
         "delivered",
         "2017-10-02T10:56:33Z",
         "2017-10-02T11:07:15Z",
         "2017-10-04T19:55:00Z",
         "2017-10-10T21:25:13Z",
         "2017-10-18T00:00:00Z"
        ],
        [
         "53cdb2fc8bc7dce0b6741e2150273451",
         "b0830fb4747a6c6d20dea0b8c802d7ef",
         "delivered",
         "2018-07-24T20:41:37Z",
         "2018-07-26T03:24:27Z",
         "2018-07-26T14:31:00Z",
         "2018-08-07T15:27:45Z",
         "2018-08-13T00:00:00Z"
        ],
        [
         "47770eb9100c2d0c44946d9cf07ec65d",
         "41ce2a54c0b03bf3443c3d931a367089",
         "delivered",
         "2018-08-08T08:38:49Z",
         "2018-08-08T08:55:23Z",
         "2018-08-08T13:50:00Z",
         "2018-08-17T18:06:29Z",
         "2018-09-04T00:00:00Z"
        ],
        [
         "949d5b44dbf5de918fe9c16f97b45f8a",
         "f88197465ea7920adcdbec7375364d82",
         "delivered",
         "2017-11-18T19:28:06Z",
         "2017-11-18T19:45:59Z",
         "2017-11-22T13:39:59Z",
         "2017-12-02T00:28:42Z",
         "2017-12-15T00:00:00Z"
        ],
        [
         "ad21c59c0840e6cb83a9ceb5573f8159",
         "8ab97904e6daea8866dbdbc4fb7aad2c",
         "delivered",
         "2018-02-13T21:18:39Z",
         "2018-02-13T22:20:29Z",
         "2018-02-14T19:46:34Z",
         "2018-02-16T18:17:02Z",
         "2018-02-26T00:00:00Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "order_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "order_status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "order_purchase_timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_approved_at",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_delivered_carrier_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_delivered_customer_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_estimated_delivery_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of orders dataframe\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43c64a6a-e52c-4865-9ef0-f1ca6efe2a4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- order_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of orders dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4605e2a4-faf9-444b-87df-245ed061477b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "99441"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in orders dataframe\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "127f84d7-3a44-40fe-af73-761a1360f4a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bronze Storage Strategy\n",
    "The raw data is stored in Delta format in the Bronze layer to enable schema enforcement, versioning, and efficient downstream processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d116bb74-0a9e-43e7-bcbf-1a95c4623c60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:190)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:465)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:750)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:84)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:84)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequest$1(Chauffeur.scala:954)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.$anonfun$applyOrElse$3(Chauffeur.scala:980)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:979)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:1034)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:834)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:830)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:825)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:189)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:186)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$5(ServerBackend.scala:175)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:23)\n",
       "\tat com.databricks.rpc.ServerBackend.executeWithLogging$1(ServerBackend.scala:148)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:997)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:917)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:557)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:522)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:1096)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:1096)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1058)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1039)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$39(ActivityContextFactory.scala:406)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:406)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:417)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)",
        "\tat scala.Option.getOrElse(Option.scala:201)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:190)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:201)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:465)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:750)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:84)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:84)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:728)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequest$1(Chauffeur.scala:954)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.$anonfun$applyOrElse$3(Chauffeur.scala:980)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:979)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:1034)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:834)",
        "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:830)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:825)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:189)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:186)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$5(ServerBackend.scala:175)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:23)",
        "\tat com.databricks.rpc.ServerBackend.executeWithLogging$1(ServerBackend.scala:148)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:997)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:917)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:557)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:522)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:1096)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:1096)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1058)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1039)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$39(ActivityContextFactory.scala:406)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:406)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:417)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write orders dataframe into bronze/ folder\n",
    "df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"overwriteSchema\", \"true\") \\\n",
    "  .save(\"abfss://olist-data@retailds.dfs.core.windows.net/bronze/orders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ac85d2f-68c2-443c-a27d-7b938e3e58ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read remaining csv file from raw/olist/ folder and write into bronze/ folder\n",
    "tables = [\n",
    "    \"customers\",\n",
    "    \"geolocation\",\n",
    "    \"order_items\",\n",
    "    \"order_payments\",\n",
    "    \"order_reviews\",\n",
    "    \"products\",\n",
    "    \"sellers\"\n",
    "\n",
    "]\n",
    "for table in tables:\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(f\"abfss://olist-data@retailds.dfs.core.windows.net/raw/olist/olist_{table}_dataset.csv\")\n",
    "\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://olist-data@retailds.dfs.core.windows.net/bronze/{table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c2450d2-8712-445f-8fb0-e702a8ae4019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>99441</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         99441
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {
             "__autoGeneratedAlias": "true"
            },
            "name": "count(1)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 14
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of rows in orders table\n",
    "spark.sql(\"\"\"select count(*) from bronze.orders\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c88123e9-de93-404b-a802-aebddbffd6c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>order_id</th><th>customer_id</th><th>order_status</th><th>order_purchase_timestamp</th><th>order_approved_at</th><th>order_delivered_carrier_date</th><th>order_delivered_customer_date</th><th>order_estimated_delivery_date</th></tr></thead><tbody><tr><td>e481f51cbdc54678b7cc49136f2d6af7</td><td>9ef432eb6251297304e76186b10a928d</td><td>delivered</td><td>2017-10-02T10:56:33Z</td><td>2017-10-02T11:07:15Z</td><td>2017-10-04T19:55:00Z</td><td>2017-10-10T21:25:13Z</td><td>2017-10-18T00:00:00Z</td></tr><tr><td>53cdb2fc8bc7dce0b6741e2150273451</td><td>b0830fb4747a6c6d20dea0b8c802d7ef</td><td>delivered</td><td>2018-07-24T20:41:37Z</td><td>2018-07-26T03:24:27Z</td><td>2018-07-26T14:31:00Z</td><td>2018-08-07T15:27:45Z</td><td>2018-08-13T00:00:00Z</td></tr><tr><td>47770eb9100c2d0c44946d9cf07ec65d</td><td>41ce2a54c0b03bf3443c3d931a367089</td><td>delivered</td><td>2018-08-08T08:38:49Z</td><td>2018-08-08T08:55:23Z</td><td>2018-08-08T13:50:00Z</td><td>2018-08-17T18:06:29Z</td><td>2018-09-04T00:00:00Z</td></tr><tr><td>949d5b44dbf5de918fe9c16f97b45f8a</td><td>f88197465ea7920adcdbec7375364d82</td><td>delivered</td><td>2017-11-18T19:28:06Z</td><td>2017-11-18T19:45:59Z</td><td>2017-11-22T13:39:59Z</td><td>2017-12-02T00:28:42Z</td><td>2017-12-15T00:00:00Z</td></tr><tr><td>ad21c59c0840e6cb83a9ceb5573f8159</td><td>8ab97904e6daea8866dbdbc4fb7aad2c</td><td>delivered</td><td>2018-02-13T21:18:39Z</td><td>2018-02-13T22:20:29Z</td><td>2018-02-14T19:46:34Z</td><td>2018-02-16T18:17:02Z</td><td>2018-02-26T00:00:00Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "e481f51cbdc54678b7cc49136f2d6af7",
         "9ef432eb6251297304e76186b10a928d",
         "delivered",
         "2017-10-02T10:56:33Z",
         "2017-10-02T11:07:15Z",
         "2017-10-04T19:55:00Z",
         "2017-10-10T21:25:13Z",
         "2017-10-18T00:00:00Z"
        ],
        [
         "53cdb2fc8bc7dce0b6741e2150273451",
         "b0830fb4747a6c6d20dea0b8c802d7ef",
         "delivered",
         "2018-07-24T20:41:37Z",
         "2018-07-26T03:24:27Z",
         "2018-07-26T14:31:00Z",
         "2018-08-07T15:27:45Z",
         "2018-08-13T00:00:00Z"
        ],
        [
         "47770eb9100c2d0c44946d9cf07ec65d",
         "41ce2a54c0b03bf3443c3d931a367089",
         "delivered",
         "2018-08-08T08:38:49Z",
         "2018-08-08T08:55:23Z",
         "2018-08-08T13:50:00Z",
         "2018-08-17T18:06:29Z",
         "2018-09-04T00:00:00Z"
        ],
        [
         "949d5b44dbf5de918fe9c16f97b45f8a",
         "f88197465ea7920adcdbec7375364d82",
         "delivered",
         "2017-11-18T19:28:06Z",
         "2017-11-18T19:45:59Z",
         "2017-11-22T13:39:59Z",
         "2017-12-02T00:28:42Z",
         "2017-12-15T00:00:00Z"
        ],
        [
         "ad21c59c0840e6cb83a9ceb5573f8159",
         "8ab97904e6daea8866dbdbc4fb7aad2c",
         "delivered",
         "2018-02-13T21:18:39Z",
         "2018-02-13T22:20:29Z",
         "2018-02-14T19:46:34Z",
         "2018-02-16T18:17:02Z",
         "2018-02-26T00:00:00Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "order_id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "customer_id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "order_status",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "order_purchase_timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "order_approved_at",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "order_delivered_carrier_date",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "order_delivered_customer_date",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "order_estimated_delivery_date",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 16
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "order_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "order_status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "order_purchase_timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_approved_at",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_delivered_carrier_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_delivered_customer_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "order_estimated_delivery_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 rows of orders table \n",
    "spark.sql(\"\"\"select * from bronze.orders limit 5\"\"\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8869317317169000,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_bronze_olist_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}